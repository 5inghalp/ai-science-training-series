{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Sklearn with Linear Models\n",
    "[Scikit-Learn](https://scikit-learn.org/) (sklearn) is the most popular library for \"conventional\" (e.g., non-deep-learning) machine learning for good reason. \n",
    "The library has an impressive collection of machine leanring algorithms and the tools needed to use them effectively in many applications, including tools that make validating a machine learning model simple. \n",
    "This notebook will start off by teaching you the fundamnetals of the \"BaseEstimator\" models and how to combine them in pipelines to create effective models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Timeless Stand-by: Linear Regression\n",
    "All machine learning models and many utility tools in sklearn all follow the same pattern defined by the \"BaseEstimator.\" \n",
    "\n",
    "### Creating a Linear Regression with the Desired Settings\n",
    "\n",
    "The first place to start out with is how to configure a \"BaseEstimator.\" Each BaseEstimator is a Python object that can be created with different settings during model creation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how printing the object's value tells you which settings are available and what their current values are. \n",
    "\n",
    "*Python Note*: Sklearn detects these options by reading the signature on the `__init__` function of the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(LinearRegression.__init__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can retrieve or set these options by setting the attributes of the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit_intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit_intercept = False\n",
    "lr.fit_intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add also through the `get_params` and `set_params` methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.set_params(fit_intercept=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These setting operations provide you different ways of changing how a machine learning model learns (e.g., `fit_intercept` controls whether we determine a non-zero intercept for the model), performance information (e.g., whether it uses more than one parallel job when evlauting the model), or other details (e.g., printing debugging information). \n",
    "\n",
    "The other kind of state an \"estimator object\" holds are the information learned from data.\n",
    "\n",
    "### Fitting a Model\n",
    "Once you define the proper settings, the next step is to use a model object to learn from data.\n",
    "\n",
    "We'll use a simple example with some linear data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.uniform(0, 10, (n_points, 1))  # 2D array with one column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 2 * X + 1 + np.random.normal(size=(n_points, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3.7, 2.5))\n",
    "\n",
    "x_plot = np.linspace(0, 10, 128)[:, None]  # Makes a 2D array\n",
    "ax.scatter(X, y, color='teal', alpha=0.5)\n",
    "\n",
    "ax.set_xlabel('$X$', fontsize=16)\n",
    "ax.set_ylabel('$y$', fontsize=16)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All machine leanring models in sklearn provide a `fit` operation that runs the machine learning algorithm to learn the weighs of the model for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X, y)  # For supervised learning, it takes the inputs and outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the information extracted from the model are stored in attributes with an underscore at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the model coefficients are close to 2, the slope we input to our model.\n",
    "\n",
    "Now that our model contains the weights needed to make predictions, we call the `predict` option on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_eval = np.linspace(0, 10, 32)[:, None]\n",
    "# [:, None] turns the array from a 1D shape (32,) to a 2D shape (32, 1).\n",
    "#  sklearn requires input arrays be 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(x_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3.7, 2.5))\n",
    "\n",
    "ax.scatter(X, y, color='teal', alpha=0.5)\n",
    "ax.plot(x_eval, y_pred, 'k')\n",
    "\n",
    "ax.set_xlabel('$X$', fontsize=16)\n",
    "ax.set_ylabel('$y$', fontsize=16)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! You've now fit your first machine leanring model.\n",
    "\n",
    "**Now it's your turn to write some code** Fit a model without `fit_intercept=False` and make predictions using `x_eval`. Name that model `lr_2` and the predictions `y_pred_2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer is hidden in the box below. Double-click to see it.\n",
    "<div  style=\"display: none;\">\n",
    "lr_2 = LinearRegression(fit_intercept=False)\n",
    "lr_2.fit(X, y)\n",
    "y_pred_2 = lr_2.predict(x_eval)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3.7, 2.5))\n",
    "\n",
    "ax.scatter(X, y, color='teal', alpha=0.5)\n",
    "ax.plot(x_eval, y_pred, 'k', label='intercept')\n",
    "ax.plot(x_eval, y_pred_2, 'r--', label='no intercept')\n",
    "\n",
    "ax.set_xlabel('$X$', fontsize=16)\n",
    "ax.set_ylabel('$y$', fontsize=16)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block will raise an error if you've made a mistake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert lr_2.intercept_ == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Performance\n",
    "The next critical element of using sklearn is to measure the performance of different models.\n",
    "\n",
    "As we'll discuss in lecture, there are many ways to measure model performance and they are all stored in the `sklearn.metrics` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, we'll compute the mean absolute error for both the \"with\" and \"without\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X)  # Predict on the points where we have training data\n",
    "lr_mae = metrics.mean_absolute_error(y_pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2 = lr_2.predict(X)  # Predict on the points where we have training data\n",
    "lr_2_mae = metrics.mean_absolute_error(y_pred_2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'With intercept: MAE={lr_mae:.1f} - Without intercept: MAE={lr_2_mae:.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your turn**: Compare the \"mean squared error\" between the two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise NotImplementedError()\n",
    "print(f'With intercept: MSE={lr_mse:.1f} - Without intercept: MAE={lr_2_mse:.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click here for answer\n",
    "\n",
    "<div style='display: none'>\n",
    "lr_mse = metrics.mean_squared_error(y, y_pred)\n",
    "lr_2_mse = metrics.mean_squared_error(y, y_pred_2)\n",
    "print(f'With intercept: MSE={lr_mse:.1f} - Without intercept: MAE={lr_2_mse:.1f}')\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Model Pipelines\n",
    "A feature in sklearn you should end up using often is the ability to put multiple steps of a machine learnng model into a [same \"Pipeline.\"](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)\n",
    "\n",
    "To demonstrate, we'll illustrate building a \"polynomial regression\" model by combining polynomial feature expansion with a linear regression model.\n",
    "\n",
    "### Explaining Polynomial Features\n",
    "To start, we'll create a quadratic dataset to learn from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = -0.6 * X * (X - 11) + np.random.normal(size=(n_points, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3, 2))\n",
    "\n",
    "x_plot = np.linspace(0, 10, 128)[:, None]  # Makes a 2D array\n",
    "ax.scatter(X, y, color='teal', alpha=0.5)\n",
    "ax.plot(x_plot, lr.predict(x_plot), 'k', lw=2)\n",
    "\n",
    "ax.set_xlabel('$X$', fontsize=16)\n",
    "ax.set_ylabel('$y$', fontsize=16)\n",
    "ax.set_ylim(0, 20)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how our linear model fails to fit it. So, let's add in some polynomial features (e.g., $X^2$, $X^3$) to make it possible to learn a non-linear model.\n",
    "\n",
    "We'll use the [`PolynomialFeatures`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) tool from sklearn to compute these features. It is also a `BaseEstimator` and, so, has the same functions for changing its settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = PolynomialFeatures(degree=3, include_bias=False)\n",
    "pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the LinearRegression model, it also has a \"fit\" function that fits any needed parameters for how to run the feature expansion (e.g., knowing how many features to output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.n_features_in_, pf.n_output_features_  # Note the \"_\" postfix used to mark \"learned attributes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of `predict`, PolynomialFeatures has a `transform` function to \"transform\" the data by creating polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly = pf.transform(X)\n",
    "X_poly[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how the first column is $x$, followed by $x^2$ and $x^3$.\n",
    "\n",
    "Now that you add these features, you can learn a linear regression model to create a polynomial regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = lr.fit(X_poly, y)  # Side note: Fitting the model again clears the old weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the model, let's use it to make predictions. Doing so requires two steps:\n",
    "1. Computing the new features\n",
    "1. Running the model on the new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_plot_poly = pf.transform(x_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_plot = lr.predict(X_plot_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(X, y, color='teal', alpha=0.5)\n",
    "ax.plot(x_plot, y_plot, 'k', lw=2)\n",
    "\n",
    "ax.set_xlabel('$X$', fontsize=16)\n",
    "ax.set_ylabel('$y$', fontsize=16)\n",
    "ax.set_ylim(0, 20)\n",
    "\n",
    "fig.set_size_inches(3, 2)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! We now have a polynomial model but it is annoying to use because we have to run two steps.\n",
    "\n",
    "### Using a Pipeline to combine transformation and learning steps\n",
    "The Pipeline object we mentioned earlier lets you define a series of pre-processing steps into the same model.\n",
    "\n",
    "Create one by defining a list of tuples of ('name of step', BaseEstimator object that does what you need)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=10)),\n",
    "    ('lr', LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the pipeline itself is a `BaseEstimator`, you can use the same methods to access and change parameters. \n",
    "\n",
    "The key thing to notice is that they add the name of the step and two underscores in front of the name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr.set_params(poly__degree=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline will run the steps you defined, passing the data from one step to the next for you. As example, let's fit and print the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_plot = pr.predict(x_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(X, y, color='teal', alpha=0.5)\n",
    "ax.plot(x_plot, y_plot, 'k', lw=2)\n",
    "\n",
    "ax.set_xlabel('$X$', fontsize=16)\n",
    "ax.set_ylabel('$y$', fontsize=16)\n",
    "ax.set_ylim(0, 20)\n",
    "\n",
    "fig.set_size_inches(3, 2)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same procedure, much less problems!\n",
    "\n",
    "## Exercise: Learning the best choice of parameters.\n",
    "To test your knowledge, finish the script I have here for finding which parameters gives you the best model.\n",
    "\n",
    "Our first step is to split our data into a training and validation set using sklearn's `train_test_split`. Given a set of X and y values plus some information on how to split them, this model will partition the data into two sets of X and y values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'X has {X.shape[0]} points, X_train has {X_train.shape[0]}, X_valid has {X_valid.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll run over many different polynomial degrees to find which degree gives the most generalizable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for n in range(1, 10):\n",
    "    # Change the polynomial degree to n\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Fit the model using X_train\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Evaluate MAE on X_train and X_valid\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    # Add the outputs to an array for tracking them\n",
    "    results.append({\n",
    "        'n': n,\n",
    "        'train_mae': train_mae,\n",
    "        'valid_mae': valid_mae\n",
    "    })\n",
    "    \n",
    "# Store the data as a Pandas DataFrame for easy analysis\n",
    "results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click for answer\n",
    "\n",
    "<div style='display: none'>\n",
    "results = []\n",
    "for n in range(1, 10):\n",
    "    # Change the polynomial degree to n\n",
    "    pr.set_params(poly__degree=n)\n",
    "    \n",
    "    # Fit the model using X_train\n",
    "    pr.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate MAE on X_train and X_valid\n",
    "    y_train_pred = pr.predict(X_train)\n",
    "    y_valid_pred = pr.predict(X_valid)\n",
    "    train_mae = metrics.mean_absolute_error(y_train, y_train_pred)\n",
    "    valid_mae = metrics.mean_absolute_error(y_valid, y_valid_pred)\n",
    "    \n",
    "    # Add the outputs to an array for tracking them\n",
    "    results.append({\n",
    "        'n': n,\n",
    "        'train_mae': train_mae,\n",
    "        'valid_mae': valid_mae\n",
    "    })\n",
    "    \n",
    "# Store the data as a Pandas DataFrame for easy analysis\n",
    "results = pd.DataFrame(results)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3.5, 2.5))\n",
    "\n",
    "ax.plot(results['n'], results['train_mae'], '--o', label='Train')\n",
    "ax.plot(results['n'], results['valid_mae'], '--s', label='Validation')\n",
    "\n",
    "ax.set_ylim(0, 6)\n",
    "\n",
    "ax.set_xlabel('Degree')\n",
    "ax.set_ylabel('MAE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how the training error gets continually lower as we add more terms, but the validation goes up after ~3 terms. The rapid increasing in error is \"overfitting.\" Our next notebooks will focus on the tools sklearn has for evaluating overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
