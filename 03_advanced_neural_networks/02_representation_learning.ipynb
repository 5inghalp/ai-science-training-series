{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca0442b2-193e-4cf0-a5c8-1e192b04f130",
   "metadata": {},
   "source": [
    "# Foundation Models\n",
    "\n",
    "The previous notebook trained a classifier network which did only ok.  But what if we didn't have a lot of data?  In this notebook, we'll apply that model in a new way with _representation learning_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba69d87a-de6c-4fba-a6e2-6de36b165b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "\n",
    "\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a551b0f7-675c-4452-97f8-36f3a269c6de",
   "metadata": {},
   "source": [
    "Here's the Convolutional Neural Network Again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8f8068c4-c85b-46d0-af2c-c665dbb6a82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class ConvNextBlock(nn.Module):\n",
    "    \"\"\"This block of operations is loosely based on this paper:\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, in_channels):\n",
    "        super(ConvNextBlock, self).__init__()\n",
    "\n",
    "        # Depthwise, seperable convolution with a large number of output filters:\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=in_channels, \n",
    "                                     out_channels=4*in_channels, \n",
    "                                     groups=in_channels,\n",
    "                                     kernel_size=[7,7],\n",
    "                                     padding='same' )\n",
    "\n",
    "        # Two more convolutions:\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=4*in_channels, \n",
    "                                     out_channels=in_channels,\n",
    "                                     kernel_size=1)\n",
    "\n",
    "        self.conv3 = torch.nn.Conv2d(in_channels=in_channels, \n",
    "                                     out_channels=in_channels,\n",
    "                                     kernel_size=1\n",
    "                                     )\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "\n",
    "        # The normalization layer:\n",
    "        x = nn.functional.layer_norm(x, x.shape)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        # The non-linear activation layer:\n",
    "        x = torch.nn.functional.gelu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        # This makes it a residual network:\n",
    "        return x + inputs\n",
    "    \n",
    "\n",
    "class Classifier(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, n_output):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "\n",
    "        # This is a downsampling convolution that will produce patches of output.\n",
    "\n",
    "        # This is similar to what vision transformers do to tokenize the images.\n",
    "        self.stem = torch.nn.Conv2d(in_channels=3,\n",
    "                                    out_channels=32,\n",
    "                                    kernel_size=4,\n",
    "                                    stride=4)\n",
    "        \n",
    "        # Apply a series of convolutional blocks:\n",
    "        self.conv_block_1 = torch.nn.Sequential(\n",
    "            ConvNextBlock(in_channels = 32,),\n",
    "            ConvNextBlock(in_channels = 32,),\n",
    "            ConvNextBlock(in_channels = 32,),\n",
    "            ConvNextBlock(in_channels = 32,),\n",
    "            ConvNextBlock(in_channels = 32,)\n",
    "        )\n",
    "\n",
    "        # Downsample the outputs:\n",
    "        self.downsample = torch.nn.Conv2d(in_channels=32, out_channels=64, \n",
    "                                          kernel_size=2, stride=2)\n",
    "\n",
    "        # Apply another series of convolutional blocks:\n",
    "        self.conv_block_2 = torch.nn.Sequential(\n",
    "            ConvNextBlock(in_channels = 64,),\n",
    "            ConvNextBlock(in_channels = 64,),\n",
    "            ConvNextBlock(in_channels = 64,),\n",
    "            ConvNextBlock(in_channels = 64,),\n",
    "            ConvNextBlock(in_channels = 64,)\n",
    "        )\n",
    "\n",
    "        # This brings it down to one channel / class\n",
    "        self.n_output = n_output\n",
    "        self.bottleneck = torch.nn.Conv2d(in_channels=64, out_channels=self.n_output, \n",
    "                                          kernel_size=1, stride=1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        x = self.stem(inputs)\n",
    "        # Apply a normalization after the initial patching:\n",
    "        x = torch.nn.functional.layer_norm(x, x.shape)\n",
    "\n",
    "        x = self.conv_block_1(x)\n",
    "\n",
    "        # Apply a normalization before downsampling:\n",
    "        x = torch.nn.functional.layer_norm(x, x.shape)\n",
    "        x = self.downsample(x)\n",
    "\n",
    "        x = self.conv_block_2(x)\n",
    "\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "\n",
    "        # Average pooling of the remaining spatial dimensions (and reshape) makes this label-like:\n",
    "        return nn.functional.avg_pool2d(x, kernel_size=x.shape[-2:]).reshape((-1,self.n_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "55fbbcfa-843e-4bcc-ba12-00d18b9e55a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Classifier                               [128, 256]                --\n",
      "├─Conv2d: 1-1                            [128, 32, 8, 8]           1,568\n",
      "├─Sequential: 1-2                        [128, 32, 8, 8]           --\n",
      "│    └─ConvNextBlock: 2-1                [128, 32, 8, 8]           --\n",
      "│    │    └─Conv2d: 3-1                  [128, 128, 8, 8]          6,400\n",
      "│    │    └─Conv2d: 3-2                  [128, 32, 8, 8]           4,128\n",
      "│    │    └─Conv2d: 3-3                  [128, 32, 8, 8]           1,056\n",
      "│    └─ConvNextBlock: 2-2                [128, 32, 8, 8]           --\n",
      "│    │    └─Conv2d: 3-4                  [128, 128, 8, 8]          6,400\n",
      "│    │    └─Conv2d: 3-5                  [128, 32, 8, 8]           4,128\n",
      "│    │    └─Conv2d: 3-6                  [128, 32, 8, 8]           1,056\n",
      "│    └─ConvNextBlock: 2-3                [128, 32, 8, 8]           --\n",
      "│    │    └─Conv2d: 3-7                  [128, 128, 8, 8]          6,400\n",
      "│    │    └─Conv2d: 3-8                  [128, 32, 8, 8]           4,128\n",
      "│    │    └─Conv2d: 3-9                  [128, 32, 8, 8]           1,056\n",
      "│    └─ConvNextBlock: 2-4                [128, 32, 8, 8]           --\n",
      "│    │    └─Conv2d: 3-10                 [128, 128, 8, 8]          6,400\n",
      "│    │    └─Conv2d: 3-11                 [128, 32, 8, 8]           4,128\n",
      "│    │    └─Conv2d: 3-12                 [128, 32, 8, 8]           1,056\n",
      "│    └─ConvNextBlock: 2-5                [128, 32, 8, 8]           --\n",
      "│    │    └─Conv2d: 3-13                 [128, 128, 8, 8]          6,400\n",
      "│    │    └─Conv2d: 3-14                 [128, 32, 8, 8]           4,128\n",
      "│    │    └─Conv2d: 3-15                 [128, 32, 8, 8]           1,056\n",
      "├─Conv2d: 1-3                            [128, 64, 4, 4]           8,256\n",
      "├─Sequential: 1-4                        [128, 64, 4, 4]           --\n",
      "│    └─ConvNextBlock: 2-6                [128, 64, 4, 4]           --\n",
      "│    │    └─Conv2d: 3-16                 [128, 256, 4, 4]          12,800\n",
      "│    │    └─Conv2d: 3-17                 [128, 64, 4, 4]           16,448\n",
      "│    │    └─Conv2d: 3-18                 [128, 64, 4, 4]           4,160\n",
      "│    └─ConvNextBlock: 2-7                [128, 64, 4, 4]           --\n",
      "│    │    └─Conv2d: 3-19                 [128, 256, 4, 4]          12,800\n",
      "│    │    └─Conv2d: 3-20                 [128, 64, 4, 4]           16,448\n",
      "│    │    └─Conv2d: 3-21                 [128, 64, 4, 4]           4,160\n",
      "│    └─ConvNextBlock: 2-8                [128, 64, 4, 4]           --\n",
      "│    │    └─Conv2d: 3-22                 [128, 256, 4, 4]          12,800\n",
      "│    │    └─Conv2d: 3-23                 [128, 64, 4, 4]           16,448\n",
      "│    │    └─Conv2d: 3-24                 [128, 64, 4, 4]           4,160\n",
      "│    └─ConvNextBlock: 2-9                [128, 64, 4, 4]           --\n",
      "│    │    └─Conv2d: 3-25                 [128, 256, 4, 4]          12,800\n",
      "│    │    └─Conv2d: 3-26                 [128, 64, 4, 4]           16,448\n",
      "│    │    └─Conv2d: 3-27                 [128, 64, 4, 4]           4,160\n",
      "│    └─ConvNextBlock: 2-10               [128, 64, 4, 4]           --\n",
      "│    │    └─Conv2d: 3-28                 [128, 256, 4, 4]          12,800\n",
      "│    │    └─Conv2d: 3-29                 [128, 64, 4, 4]           16,448\n",
      "│    │    └─Conv2d: 3-30                 [128, 64, 4, 4]           4,160\n",
      "├─Conv2d: 1-5                            [128, 256, 4, 4]          16,640\n",
      "==========================================================================================\n",
      "Total params: 251,424\n",
      "Trainable params: 251,424\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 880.41\n",
      "==========================================================================================\n",
      "Input size (MB): 1.57\n",
      "Forward/backward pass size (MB): 101.71\n",
      "Params size (MB): 1.01\n",
      "Estimated Total Size (MB): 104.29\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "model = Classifier(256)\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "print(summary(model, input_size=(batch_size, 3, 32, 32)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691caee3-bb58-451b-b3d7-fc394393b95f",
   "metadata": {},
   "source": [
    "This will download the data if needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "422c5c32-2d59-47b4-9e69-249451f3f410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "training_data = torchvision.datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "\n",
    "test_data = torchvision.datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "\n",
    "training_data, validation_data = torch.utils.data.random_split(training_data, [0.8, 0.2], generator=torch.Generator().manual_seed(55))\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "# The dataloader makes our dataset iterable \n",
    "train_dataloader = torch.utils.data.DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(validation_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eeb11a6-e248-4223-bc06-ef995f658ec8",
   "metadata": {},
   "source": [
    "\n",
    "We're going to train this on Polaris nodes which have 4 A100s (But only using one node at a time).  So, the following helper functions will automatically distribute the code and model to use all 4 GPUs at once:\n",
    "\n",
    "(They are all from the [DDP Tutorial](https://pytorch.org/tutorials/intermediate/ddp_tutorial.html) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "562b9ac3-52cf-4ee4-8e36-cd7c4b29c51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def setup(rank, world_size):\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12355'\n",
    "\n",
    "    # initialize the process group\n",
    "    dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)\n",
    "\n",
    "def cleanup():\n",
    "    dist.destroy_process_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "24e2ebd9-47f7-4534-b67a-7ca43b9bc98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loaders(transforms, batch_size, rank):\n",
    "    # Start up the data loader:\n",
    "    dev = torch.device(\n",
    "        f\"cuda:{rank}\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "    training_data = torchvision.datasets.CIFAR10(\n",
    "        root=\"data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms\n",
    "    )\n",
    "    \n",
    "    test_data = torchvision.datasets.CIFAR10(\n",
    "        root=\"data\",\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms\n",
    "    )\n",
    "    \n",
    "    training_data, validation_data = torch.utils.data.random_split(training_data, [0.8, 0.2], generator=torch.Generator().manual_seed(55))\n",
    "    \n",
    "    \n",
    "    # The dataloader makes our dataset iterable \n",
    "    train_dataloader = torch.utils.data.DataLoader(training_data, batch_size=batch_size, shuffle=False)\n",
    "    val_dataloader = torch.utils.data.DataLoader(validation_data, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "\n",
    "    def preprocess(x, y):\n",
    "        # CIFAR-10 is *color* images so 3 layers!\n",
    "        return x.view(-1, 3, 32, 32).to(dev), y.to(dev)\n",
    "    \n",
    "    \n",
    "    class WrappedDataLoader:\n",
    "        def __init__(self, dl, func):\n",
    "            self.dl = dl\n",
    "            self.func = func\n",
    "    \n",
    "        def __len__(self):\n",
    "            return len(self.dl)\n",
    "    \n",
    "        def __iter__(self):\n",
    "            for b in self.dl:\n",
    "                yield (self.func(*b))\n",
    "\n",
    "\n",
    "    train_dataloader = WrappedDataLoader(train_dataloader, preprocess)\n",
    "    val_dataloader = WrappedDataLoader(val_dataloader, preprocess)\n",
    "\n",
    "    return train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4c5fcdae-fbe6-4e0b-b3d7-e8b771e9ee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def demo_basic(rank, world_size, n_epochs):\n",
    "    print(f\"Running basic DDP example on rank {rank}.\")\n",
    "    setup(rank, world_size)\n",
    "\n",
    "    \n",
    "    # create model and move it to GPU with id rank\n",
    "    model = ToyModel().to(rank)\n",
    "    ddp_model = DDP(model, device_ids=[rank])\n",
    "\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = ddp_model(torch.randn(20, 10))\n",
    "    labels = torch.randn(20, 5).to(rank)\n",
    "    loss_fn(outputs, labels).backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    cleanup()\n",
    "\n",
    "\n",
    "def run_demo(demo_fn, world_size):\n",
    "    mp.spawn(demo_fn,\n",
    "             args=(world_size,5),\n",
    "             nprocs=world_size,\n",
    "             join=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544004df-e1f3-4ee3-b37e-0e3dce527da1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "11354136-05f8-4297-908c-fc35ff0a828a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing.reduction import ForkingPickler\n",
    "from types import FunctionType\n",
    "import cloudpickle\n",
    "\n",
    "assert sys.version_info >= (3, 8), 'python3.8 or greater required to use reducer_override'\n",
    "\n",
    "def reducer_override(obj):\n",
    "    if type(obj) is FunctionType:\n",
    "        return (cloudpickle.loads, (cloudpickle.dumps(obj),))\n",
    "    else:\n",
    "        return NotImplemented\n",
    "\n",
    "# Monkeypatch our function reducer into the pickler for multiprocessing.\n",
    "# Without this line, the main block will not work on windows or macOS.\n",
    "# Alterntively, moving the defintionn of foo outside of the if statement\n",
    "# would make the main block work on windows or macOS (when run from\n",
    "# the command line).\n",
    "ForkingPickler.reducer_override = staticmethod(reducer_override)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d9716224-0de3-4e52-85e8-7f6e26763c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running basic DDP example on rank 3.\n",
      "Running basic DDP example on rank 0.\n",
      "Running basic DDP example on rank 1.\n",
      "Running basic DDP example on rank 2.\n"
     ]
    },
    {
     "ename": "ProcessRaisedException",
     "evalue": "\n\n-- Process 0 terminated with the following error:\nTraceback (most recent call last):\n  File \"/soft/datascience/conda/2023-10-04/mconda3/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 69, in _wrap\n    fn(i, *args)\n  File \"/var/tmp/pbs.1281461.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov/ipykernel_7640/408412622.py\", line 7, in demo_basic\nNameError: name 'ToyModel' is not defined\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProcessRaisedException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_demo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdemo_basic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[81], line 23\u001b[0m, in \u001b[0;36mrun_demo\u001b[0;34m(demo_fn, world_size)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_demo\u001b[39m(demo_fn, world_size):\n\u001b[0;32m---> 23\u001b[0m     \u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspawn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdemo_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m             \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m             \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworld_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m             \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/soft/datascience/conda/2023-10-04/mconda3/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:239\u001b[0m, in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    235\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis method only supports start_method=spawn (got: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    236\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTo use a different start_method use:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    237\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m torch.multiprocessing.start_processes(...)\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m start_method)\n\u001b[1;32m    238\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg)\n\u001b[0;32m--> 239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstart_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdaemon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspawn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/soft/datascience/conda/2023-10-04/mconda3/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:197\u001b[0m, in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# Loop on join until it returns True or raises an exception.\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/soft/datascience/conda/2023-10-04/mconda3/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:160\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    158\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-- Process \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with the following error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m error_index\n\u001b[1;32m    159\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m original_trace\n\u001b[0;32m--> 160\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ProcessRaisedException(msg, error_index, failed_process\u001b[38;5;241m.\u001b[39mpid)\n",
      "\u001b[0;31mProcessRaisedException\u001b[0m: \n\n-- Process 0 terminated with the following error:\nTraceback (most recent call last):\n  File \"/soft/datascience/conda/2023-10-04/mconda3/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 69, in _wrap\n    fn(i, *args)\n  File \"/var/tmp/pbs.1281461.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov/ipykernel_7640/408412622.py\", line 7, in demo_basic\nNameError: name 'ToyModel' is not defined\n"
     ]
    }
   ],
   "source": [
    "run_demo(demo_basic, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066d1b3a-f159-430d-81c8-05957ca3824f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "demo_basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda19fe1-3e37-45b6-8bb6-574bee4b5595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "# This method is from the pytorch implementation of SimCLR:\n",
    "# https://github.com/sthalles/SimCLR/blob/master/data_aug/contrastive_learning_dataset.py\n",
    "\n",
    "def get_simclr_pipeline_transform(size, s=1):\n",
    "    \"\"\"Return a set of data augmentation transformations as described in the SimCLR paper.\"\"\"\n",
    "    color_jitter = transforms.ColorJitter(0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s)\n",
    "    data_transforms = transforms.Compose([\n",
    "                                          # transforms.RandomResizedCrop(size=size),\n",
    "                                          transforms.RandomHorizontalFlip(),\n",
    "                                          transforms.RandomApply([color_jitter], p=0.8),\n",
    "                                          transforms.RandomGrayscale(p=0.2),\n",
    "                                          transforms.ToTensor()])\n",
    "    return data_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67638fcb-43c7-4c45-a8e6-284998ea6ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms1 = get_simclr_pipeline_transform((32,32))\n",
    "transforms2 = get_simclr_pipeline_transform((32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a279ed33-e4e3-4f33-96f9-05971cc75551",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1, val1 = create_data_loaders(transforms1, 128, 0)\n",
    "train2, val2 = create_data_loaders(transforms2, 128, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3d388c-2226-49f4-b185-825c9048f773",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch, (X1, Y1) = next(enumerate(train1))\n",
    "batch, (X2, Y2) = next(enumerate(train2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59b8dd8-10d2-4a7a-a321-1456eb27c0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1085f655-7e32-449c-801c-3a73a74815b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x150692285630>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X1[0].cpu().permute((1,2,0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "10ec2a9e-08d0-4569-8175-a4f3062a1228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x150698f42560>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X2[0].cpu().permute((1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7f813d20-e3f7-47c3-b4c5-7831f3c4ce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(net, X1, X2):\n",
    "\n",
    "    rep1 = net(X1)\n",
    "    rep2 = net(X2)\n",
    "\n",
    "    return rep1, rep2\n",
    "\n",
    "def contrastive_loss(first_images, second_images, rank, world_size = 1, temperature=0.1):\n",
    "        # Each image is represented with k parameters,\n",
    "        # Assume the batch size is N, so the\n",
    "        # inputs have shape (N, k)\n",
    "\n",
    "        # These are pre-distributed shapes:\n",
    "        N = first_images.shape[0]\n",
    "        k = first_images.shape[1]\n",
    "\n",
    "\n",
    "        first_images = first_images / torch.norm(first_images,dim=1).reshape((-1,1))\n",
    "        second_images = second_images / torch.norm(second_images,dim=1).reshape((-1,1))\n",
    "\n",
    "        # Take the two tuples, and concatenate them.\n",
    "        # Then, reshape into Y = (1, 2N, k) and Z = (2N, 1, k)\n",
    "\n",
    "        c = torch.concat([first_images, second_images], dim=0)\n",
    "\n",
    "        # Gather all the c up if the world size > 1:\n",
    "        if world_size > 1:\n",
    "            gathered_c = torch.distributed.all_gather(tensor=c)\n",
    "            gathered_c = gathered_c.reshape((-1, first_images.shape[-1]))\n",
    "        else:\n",
    "            gathered_c = c\n",
    "\n",
    "        # Each rank computes only a slice of the global loss matrix, or\n",
    "        # the memory usage gets out of control.\n",
    "\n",
    "        # We calculate the dot product between the local and global tensors:\n",
    "        local_reps = c.reshape((c.shape[0], 1, c.shape[1]))\n",
    "        all_reps   = gathered_c.reshape((1, gathered_c.shape[0], gathered_c.shape[1]))\n",
    "\n",
    "\n",
    "        # Assume we have n images per rank, for N global images with N = n * world_size\n",
    "        # Compute the product of these tensors, which gives shape\n",
    "        # (2n, 2N, k)\n",
    "        mat =  local_reps*all_reps\n",
    "\n",
    "        # We need to compute the function (sim(x,y)) for each element in the 2N sequent.\n",
    "        # Since the are normalized, we're computing x^T . Y / (||x||*||y||),\n",
    "        # but the norms are equal to 1.\n",
    "        # So, summing the matrix over the dim = 0 and dim = 1 computes this for each pair.\n",
    "\n",
    "        sim = torch.sum(mat, dim=-1) / temperature\n",
    "\n",
    "\n",
    "\n",
    "        # Now, sim is of shape [2*n, 2*N]\n",
    "\n",
    "        # This yields a symmetric matrix, diagonal entries equal 1.  Off diagonal are symmetrics and < 1.\n",
    "\n",
    "        # sim = torch.exp(sim / temperature)\n",
    "        # Now, for every entry i in C (concat of both batches), the sum of sim[i] - sim[i][i] is the denominator\n",
    "\n",
    "        device = sim.device\n",
    "\n",
    "        # Since we have a non-symmetric matrix, need to build a non-symmetric index:\n",
    "        positive = torch.zeros(sim.shape, device=device)\n",
    "\n",
    "        # We concatenated all the local examples, and compute symmetric positive pairs\n",
    "        # So for the first N entries, the index of the positive pair is i + N  (locally)\n",
    "        # For the second N entries, the index of the positive pair is i - N (locally)\n",
    "        # with a distributed run, we've squashed all the similarity scores together.\n",
    "        # to a shape of [2*N, 2*N*Size]\n",
    "        # Each 2*N by 2*N block is the local positive indexes, all others are negative.\n",
    "        # That means that the index is shifted by global_rank*2*N\n",
    "\n",
    "        access_index_x = torch.arange(2*N)\n",
    "        # For the first N, the y-index is equal to x + 2*N\n",
    "        # For the second N\n",
    "        access_index_y = torch.arange(2*N)\n",
    "        # Shift by +/- N:\n",
    "        access_index_y[0:N] = access_index_y[0:N] + N\n",
    "        access_index_y[N:]  = access_index_y[N:] - N\n",
    "\n",
    "        access_index_y +=  rank * 2*N\n",
    "\n",
    "        # print(\"access_index_y: \", access_index_y, flush=True)\n",
    "\n",
    "        positive[access_index_x, access_index_y] = 1\n",
    "\n",
    "        # For the negative, we invert the positive and have to 0 out the self-index entries\n",
    "        negative = 1 - positive\n",
    "\n",
    "        # THESE WORK IF IT'S NOT DISTRIBUTED\n",
    "        # positive = torch.tile(torch.eye(N, device=device), (2,2))\n",
    "        # # Unsure if this line is needed?\n",
    "        # positive = positive - torch.eye(2*N, device=device)\n",
    "        #\n",
    "        # negative = - (torch.eye(2*N, device=device) - 1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Here, we can compute the top-k metrics for this batch, since we have the global state:\n",
    "            # We want the top 5 entries but the self-sim is obviously perfect.\n",
    "            # So take the top 6 and reject the first.\n",
    "            topk = torch.topk(sim, k=6, dim=-1, sorted=True)\n",
    "\n",
    "            # Top 1 is just an equality check:\n",
    "            top1_acc = topk.indices[:,1] == access_index_y.to(topk.indices.device)\n",
    "            top1_acc = torch.mean(top1_acc.to(torch.float))\n",
    "          \n",
    "            # Top 5 is a little more complicated:\n",
    "            # Compute the index distance to the correct index, abs value:\n",
    "            top5_acc_dist = torch.abs(topk.indices[:,1:] - access_index_y.to(topk.indices.device).reshape(-1,1))\n",
    "            # Get the minumum value, and see if it is less than 5:\n",
    "            min_values, _ = torch.min(top5_acc_dist, dim=-1)\n",
    "            top5_acc =  min_values < 5.\n",
    "            # Average over the batch dimension:\n",
    "            top5_acc = torch.mean(top5_acc.to(torch.float))\n",
    "\n",
    "\n",
    "        negative_examples = sim * negative\n",
    "        positive_examples = sim * positive\n",
    "\n",
    "        # Now, positive/negative examples is the temperature normalized similarity.\n",
    "        # we need to sum across the whole batch dimension to compute it per-example:\n",
    "\n",
    "\n",
    "        # Compute the alignment, summed over the entire global batch:\n",
    "        alignment = torch.sum(positive_examples, dim=-1)\n",
    "\n",
    "        # Compute the exp, which we'll eventually sum and log:\n",
    "        exp = torch.sum(torch.exp(negative_examples), dim=-1)\n",
    "\n",
    "        # print(\"Alignment: \", alignment, flush=True)\n",
    "        # print(\"exp: \",       exp, flush=True)\n",
    "\n",
    "\n",
    "        # And compute the logsumexp of the negative examples:\n",
    "        log_sum_exp = torch.log(exp )\n",
    "\n",
    "\n",
    "        # Additionally, we can compute the \"floor\" of the loss at this batch size:\n",
    "        # floor = torch.log(1.*N) - 1.\n",
    "\n",
    "        loss_metrics = {\n",
    "            \"alignment\"   : torch.mean(alignment),\n",
    "            \"log_sum_exp\" : torch.mean(log_sum_exp),\n",
    "            \"top1\"        : top1_acc,\n",
    "            \"top5\"        : top5_acc,\n",
    "            # \"floor\"       : floor,\n",
    "        }\n",
    "\n",
    "        loss = torch.mean( - alignment + log_sum_exp)\n",
    "        return loss, loss_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4135ea73-85b0-431d-b942-61e9bfbd340d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 256])\n"
     ]
    }
   ],
   "source": [
    "rep1, rep2 = forward(model, X1, X2)\n",
    "print(rep1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "06e321f3-7cb3-43cd-bd0e-416234443a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, metrics = contrastive_loss(rep1, rep2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "eb095e0b-e965-4d66-90bc-23b279f32034",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "72478d32-f057-4808-92b7-3a6da64fa9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (stem): Conv2d(3, 32, kernel_size=(4, 4), stride=(4, 4))\n",
       "  (conv_block_1): Sequential(\n",
       "    (0): ConvNextBlock(\n",
       "      (conv1): Conv2d(32, 128, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=32)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (1): ConvNextBlock(\n",
       "      (conv1): Conv2d(32, 128, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=32)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (2): ConvNextBlock(\n",
       "      (conv1): Conv2d(32, 128, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=32)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (3): ConvNextBlock(\n",
       "      (conv1): Conv2d(32, 128, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=32)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (4): ConvNextBlock(\n",
       "      (conv1): Conv2d(32, 128, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=32)\n",
       "      (conv2): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (downsample): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (conv_block_2): Sequential(\n",
       "    (0): ConvNextBlock(\n",
       "      (conv1): Conv2d(64, 256, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=64)\n",
       "      (conv2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (1): ConvNextBlock(\n",
       "      (conv1): Conv2d(64, 256, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=64)\n",
       "      (conv2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (2): ConvNextBlock(\n",
       "      (conv1): Conv2d(64, 256, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=64)\n",
       "      (conv2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (3): ConvNextBlock(\n",
       "      (conv1): Conv2d(64, 256, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=64)\n",
       "      (conv2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (4): ConvNextBlock(\n",
       "      (conv1): Conv2d(64, 256, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=64)\n",
       "      (conv2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (bottleneck): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f602adb-f56a-48af-ba08-fad3b3020236",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
