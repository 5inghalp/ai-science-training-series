{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b312438",
   "metadata": {},
   "source": [
    "# Generative Models\n",
    "\n",
    "A generative model could be loosely defined as any model that takes an abstract, low dimensional input and outputs a high dimensional image as a result.  In this definition, the autoencoders we developed in the first tutorials count as generative networks.  But if you feed in random data, you are unlikely to get good output!\n",
    "\n",
    "Generative Adversarial Networks create generative models through a different technique.  These networks take points from a random input distribution - say, N random values between 0 and 1.  They feed these values forward through the network, and the output of the network is an image that is - ideally - indistinguishable from the real images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d11cd22",
   "metadata": {},
   "source": [
    "## Training a Generative Adversarial Network\n",
    "\n",
    "You can build a generative model using an adversarial training technique.  This has been around for some time now, but the key components of the training process are this:\n",
    " - Two networks are created.  \n",
    "     - One is a __generator__, which is tasked with taking random input (Let's say we give it a tensor of shape 50, with each value in the range (0, 1) ) and outputing an image (shape 28x28 as usual) which is indistinguishable from the handwritten digits in the mnist dataset.\n",
    "     - The second network is a __discriminator__ or classifier which takes as input images and has to decide on a case-by-case basis which images are from the real dataset, and which images are from the __generator__.\n",
    " - During training, first the generator is run and it produces a set of output images.\n",
    " - Next, a set of *real* images is pulled from the dataset and augments the generated images.  Each image is given a label of 1 for fake, 0 for real.\n",
    " - The __discriminator__ runs and classifies the images as best it can, either real or fake.\n",
    " - The gradients of the __discriminator__ are updated easily, as it is just a classification problem.\n",
    " - The gradients of the __generator__ are then updated based on the success or failure of the discriminator.  In this way, the __generator__ is trained directly to trick the discriminator into believing the wrong images are real.\n",
    " \n",
    "At the end of the training session, the discriminator network can usually be discarded while the generator remains as an interesting network.  You can use it moving forward to generate new fake data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973c5cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884f2364",
   "metadata": {},
   "source": [
    "The network designs for a GAN need not be anything special. We will use very similar networks as before in our convolutional auto encoder, but the key difference will be how the networks are trained.  Let's start with our discriminator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed3be3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(tf.keras.models.Model):\n",
    "    '''\n",
    "    Simple classifier for mnist, but only 1 or 2 outputs:\n",
    "        \n",
    "    With 1 output, we will use a sigmoid cross entropy.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, activation=tf.nn.tanh):\n",
    "        tf.keras.models.Model.__init__(self)\n",
    "\n",
    "        # Apply a 5x5 kernel to the image:\n",
    "        self.discriminator_layer_1 = tf.keras.layers.Convolution2D(\n",
    "            kernel_size = [5, 5], \n",
    "            filters     = 24,\n",
    "            padding     = \"same\",\n",
    "            activation  = activation,\n",
    "        )\n",
    "        \n",
    "        self.dropout_1 = tf.keras.layers.Dropout(0.4)\n",
    "        \n",
    "        self.pool_1 = tf.keras.layers.MaxPool2D()\n",
    "        \n",
    "        self.discriminator_layer_2 = tf.keras.layers.Convolution2D(\n",
    "            kernel_size = [5, 5], \n",
    "            filters     = 64, \n",
    "            padding     = \"same\",\n",
    "            activation  = activation,\n",
    "        )\n",
    "\n",
    "        self.dropout_2 = tf.keras.layers.Dropout(0.4)\n",
    "        \n",
    "        self.pool_2 = tf.keras.layers.MaxPool2D()\n",
    "\n",
    "        self.discriminator_layer_3 = tf.keras.layers.Convolution2D(\n",
    "            kernel_size = [5, 5],\n",
    "            filters     = 128,\n",
    "            padding     = \"same\",\n",
    "            activation  = activation,\n",
    "        )\n",
    "        \n",
    "        self.dropout_3 = tf.keras.layers.Dropout(0.4)\n",
    "\n",
    "        \n",
    "        self.pool_3 = tf.keras.layers.MaxPool2D()\n",
    "\n",
    "        self.discriminator_layer_final = tf.keras.layers.Dense(\n",
    "            units = 1,\n",
    "            activation = None,\n",
    "            )\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        batch_size = inputs.shape[0]\n",
    "        x = inputs\n",
    "        # Make sure the input is the right shape:\n",
    "        x = tf.reshape(x, [batch_size, 28, 28, 1])\n",
    "            \n",
    "        x = self.discriminator_layer_1(x)\n",
    "        x = self.pool_1(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.discriminator_layer_2(x)\n",
    "        x = self.pool_2(x)\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.discriminator_layer_3(x)\n",
    "        x = self.pool_3(x)\n",
    "        x = self.dropout_3(x)\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        x = self.discriminator_layer_final(x)\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0d1638",
   "metadata": {},
   "source": [
    "And here is our generator model, which will expect as input some random-number fixed length tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15863724",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(tf.keras.models.Model):\n",
    "    \n",
    "    def __init__(self, activation=tf.nn.tanh):\n",
    "        tf.keras.models.Model.__init__(self)\n",
    "\n",
    "        # The first step is to take the random image and use a dense layer to \n",
    "        #make it the right shape\n",
    "        \n",
    "        self.dense = tf.keras.layers.Dense(\n",
    "            units = 7 * 7 * 64\n",
    "        )\n",
    "        \n",
    "        # This will get reshaped into a 7x7 image with 64 filters.\n",
    "        \n",
    "        # We need to upsample twice to get to a full 28x28 resolution image\n",
    "        \n",
    "        \n",
    "        self.batch_norm_1 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        \n",
    "        self.generator_layer_1 = tf.keras.layers.Convolution2D(\n",
    "            kernel_size = [5, 5],\n",
    "            filters     = 64,\n",
    "            padding     = \"same\",\n",
    "            use_bias    = True,\n",
    "            kernel_regularizer = tf.keras.regularizers.L2(),\n",
    "            activation  = activation,\n",
    "        )\n",
    "        \n",
    "        self.unpool_1 = tf.keras.layers.UpSampling2D(\n",
    "            size          = 2,\n",
    "            interpolation = \"nearest\",\n",
    "        )\n",
    "        \n",
    "        # After that unpooling the shape is [14, 14] with 64 filters\n",
    "        self.batch_norm_2 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "\n",
    "        self.generator_layer_2 = tf.keras.layers.Convolution2D(\n",
    "            kernel_size = [5, 5],\n",
    "            filters     = 32,\n",
    "            padding     = \"same\",\n",
    "            use_bias    = True,\n",
    "            kernel_regularizer = tf.keras.regularizers.L2(),\n",
    "            activation  = activation,\n",
    "        )\n",
    "        \n",
    "        self.unpool_2 = tf.keras.layers.UpSampling2D(\n",
    "            size          = 2,\n",
    "            interpolation = \"nearest\",\n",
    "        )\n",
    "\n",
    "        self.batch_norm_3 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "\n",
    "        self.generator_layer_3 = tf.keras.layers.Convolution2D(\n",
    "            kernel_size = [5, 5],\n",
    "            filters     = 8,\n",
    "            padding     = \"same\",\n",
    "            use_bias    = True,\n",
    "            kernel_regularizer = tf.keras.regularizers.L2(),\n",
    "            activation  = activation,\n",
    "        )\n",
    "        \n",
    "        # Now it is [28, 28] by 24 filters, use a bottle neck to \n",
    "        # compress to a single image:\n",
    "        self.batch_norm_4 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "\n",
    "        self.generator_layer_final = tf.keras.layers.Convolution2D(\n",
    "            kernel_size = [5, 5],\n",
    "            filters     = 1,\n",
    "            padding     = \"same\",\n",
    "            use_bias    = True,\n",
    "            kernel_regularizer = tf.keras.regularizers.L2(),\n",
    "            activation  = tf.nn.sigmoid,\n",
    "        )\n",
    "        \n",
    "\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        ''' \n",
    "        Reshape at input and output: \n",
    "        '''\n",
    "            \n",
    "        \n",
    "        batch_size = inputs.shape[0]\n",
    "\n",
    "\n",
    "        x = self.dense(inputs)\n",
    "\n",
    "\n",
    "        # First Step is to to un-pool the encoded state into the right shape:\n",
    "        x = tf.reshape(x, [batch_size, 7, 7, 64])\n",
    "\n",
    "        x = self.batch_norm_1(x)\n",
    "        x = self.generator_layer_1(x)\n",
    "        x = self.unpool_1(x)\n",
    "        x = self.batch_norm_2(x)\n",
    "        x = self.generator_layer_2(x)\n",
    "        x = self.unpool_2(x)\n",
    "        x = self.batch_norm_3(x)\n",
    "        x = self.generator_layer_3(x)\n",
    "        x = self.batch_norm_4(x)\n",
    "        x = self.generator_layer_final(x)\n",
    "        \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce57a359",
   "metadata": {},
   "source": [
    "Ok, let's run our networks forward and backwards to see the network parameters:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d4151d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a05704",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_input = numpy.random.uniform(-1,1,[1,100]).astype(numpy.float32)\n",
    "generated_image = generator(random_input)\n",
    "generator.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece87157",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator()\n",
    "classification  = discriminator(generated_image)\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f29385",
   "metadata": {},
   "source": [
    "Let's again take a look at the output images before training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb046e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(generated_image.numpy().reshape([28,28]))\n",
    "print(numpy.min(generated_image.numpy()))\n",
    "print(numpy.max(generated_image.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20225073",
   "metadata": {},
   "source": [
    "Just random noise!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e3c490",
   "metadata": {},
   "source": [
    "## Helper functions for training\n",
    "\n",
    "Training a GAN takes some care in bookkeeping since you are training two models simultaneously.  So let's lay out some functions to keep things neat and organized.\n",
    "\n",
    "**Throughout, we're using 0 to  mean fake and 1 to mean real**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d722da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the mnist data so we have it loaded globally:\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.astype(numpy.float32)\n",
    "x_test  = x_test.astype(numpy.float32)\n",
    "\n",
    "x_train /= 255.\n",
    "x_test  /= 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693bc039",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numpy.min(x_train))\n",
    "print(numpy.max(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9b5530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(_logits, _targets):\n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=_targets, logits=_logits)\n",
    "    \n",
    "    return tf.reduce_mean(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a54398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_real_batch(_batch_size):\n",
    "    indexes = numpy.random.choice(a=x_train.shape[0], size=[_batch_size,])\n",
    "    \n",
    "    images = x_train[indexes].reshape(_batch_size, 28, 28, 1)\n",
    "    labels = y_train[indexes]\n",
    "    \n",
    "    return images, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b0eca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(_generator, _discriminator, _batch_size, _input_size, _lie_rate):\n",
    "        '''\n",
    "        This function takes the two models and runs a forward pass to the computation of the loss functions\n",
    "        '''\n",
    "\n",
    "        # Fetch real data:\n",
    "        real_data, _ = fetch_real_batch(_batch_size)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Use the generator to make fake images:\n",
    "        random_noise = numpy.random.uniform(-1, 1, size=_batch_size*_input_size).astype(numpy.float32)\n",
    "        random_noise = random_noise.reshape([_batch_size, _input_size])\n",
    "        fake_images  = _generator(random_noise)\n",
    "        \n",
    "\n",
    "        # Use the discriminator to make a prediction on the REAL data:\n",
    "        prediction_on_real_data = _discriminator(real_data)\n",
    "        # Use the discriminator to make a prediction on the FAKE data:\n",
    "        prediction_on_fake_data = _discriminator(fake_images)\n",
    "        \n",
    "\n",
    "        soften = 0.1\n",
    "        real_labels = numpy.zeros([_batch_size,1], dtype=numpy.float32) + soften\n",
    "        fake_labels = numpy.ones([_batch_size,1],  dtype=numpy.float32) - soften\n",
    "        gen_labels  = numpy.zeros([_batch_size,1], dtype=numpy.float32)\n",
    "\n",
    "\n",
    "        # Occasionally, we disrupt the discriminator (since it has an easier job)\n",
    "        \n",
    "        # Invert a few of the discriminator labels:\n",
    "        \n",
    "        n_swap = int(_batch_size * _lie_rate)\n",
    "        \n",
    "        real_labels [0:n_swap] = 1.\n",
    "        fake_labels [0:n_swap] = 0.\n",
    "        \n",
    "        \n",
    "        # Compute the loss for the discriminator on the real images:\n",
    "        discriminator_real_loss = compute_loss(\n",
    "            _logits  = prediction_on_real_data, \n",
    "            _targets = real_labels)\n",
    "        \n",
    "        # Compute the loss for the discriminator on the fakse images:\n",
    "        discriminator_fake_loss = compute_loss(\n",
    "            _logits  = prediction_on_fake_data, \n",
    "            _targets = fake_labels)\n",
    "\n",
    "        # The generator loss is based on the output of the discriminator.\n",
    "        # It wants the discriminator to pick the fake data as real\n",
    "        generator_target_labels = [1] * _batch_size\n",
    "        \n",
    "        generator_loss = compute_loss(\n",
    "            _logits  = prediction_on_fake_data, \n",
    "            _targets = real_labels)\n",
    "        \n",
    "        # Average the discriminator loss:\n",
    "        discriminator_loss = 0.5*(discriminator_fake_loss  + discriminator_real_loss)\n",
    "        \n",
    "        # Calculate the predicted label (real or fake) to calculate the accuracy:\n",
    "        predicted_real_label = numpy.argmax(prediction_on_real_data.numpy(), axis=-1)\n",
    "        predicted_fake_label = numpy.argmax(prediction_on_fake_data.numpy(), axis=-1)\n",
    "\n",
    "        discriminator_accuracy = 0.5 * numpy.mean(predicted_real_label == real_labels) + \\\n",
    "            0.5 * numpy.mean(predicted_fake_label == fake_labels)\n",
    "        generator_accuracy = 0.5 * numpy.mean(predicted_fake_label == generator_target_labels)\n",
    "          \n",
    "        \n",
    "        metrics = {\n",
    "            \"discriminator\" : discriminator_accuracy,\n",
    "            \"generator\"    : generator_accuracy\n",
    "        }\n",
    "\n",
    "        loss = {\n",
    "            \"discriminator\" : discriminator_loss,\n",
    "            \"generator\"    : generator_loss        \n",
    "        }\n",
    "        \n",
    "        images = {\n",
    "            \"real\" : real_data[0].reshape([28,28]),\n",
    "            \"fake\" : fake_images.numpy()[0].reshape([28,28]) \n",
    "        }\n",
    "\n",
    "        \n",
    "        return loss, metrics, images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6de8c2b",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3268546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a function that will manage the training loop for us:\n",
    "\n",
    "def train_loop(batch_size, n_training_iterations, models, opts, lie_rate):\n",
    "\n",
    "\n",
    "\n",
    "    # Create a plot that updates:\n",
    "    fig = plt.figure(figsize=(16, 9))\n",
    "    ax_loss = fig.add_subplot(131)\n",
    "    ax_real = fig.add_subplot(132)\n",
    "    ax_fake = fig.add_subplot(133)\n",
    "\n",
    "    steps = []\n",
    "    loss_history = {\n",
    "        \"generator\" : [],\n",
    "        \"discriminator\" : []\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(n_training_iterations):\n",
    "\n",
    "        for network in [\"generator\", \"discriminator\"]:\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                    loss, metrics, images = forward_pass(\n",
    "                        models[\"generator\"],\n",
    "                        models[\"discriminator\"], \n",
    "                        _input_size = 100,\n",
    "                        _batch_size = BATCH_SIZE,\n",
    "                        _lie_rate   = lie_rate,\n",
    "                    )\n",
    "\n",
    "\n",
    "            if loss[\"discriminator\"] < 0.01:\n",
    "                break\n",
    "\n",
    "\n",
    "            steps.append(i)\n",
    "            loss_history[\"generator\"].append(loss[\"generator\"].numpy())\n",
    "            loss_history[\"discriminator\"].append(loss[\"discriminator\"].numpy())\n",
    "\n",
    "\n",
    "            trainable_vars = models[network].trainable_variables\n",
    "\n",
    "            # Apply the update to the network:\n",
    "            grads = tape.gradient(loss[network], trainable_vars)\n",
    "\n",
    "            opts[network].apply_gradients(zip(grads, trainable_vars))\n",
    "\n",
    "\n",
    "        if i % 25 == 0:\n",
    "            # Update plots:\n",
    "            ax_loss.cla()\n",
    "            ax_loss.plot(steps, loss_history[\"generator\"], label=\"Generator Loss\")\n",
    "            ax_loss.plot(steps, loss_history[\"discriminator\"], label=\"Discriminator Loss\")\n",
    "            ax_loss.grid(True)\n",
    "            ax_loss.legend()\n",
    "            ax_real.imshow(images['real'],vmin=0, vmax=1)\n",
    "            ax_real.set_title(\"Real\", fontsize=20)\n",
    "            ax_fake.imshow(images['fake'],vmin=0, vmax=1)\n",
    "            ax_fake.set_title(\"Fake\", fontsize=20)\n",
    "            clear_output(wait = True)\n",
    "            display(fig)\n",
    "            plt.pause(0.1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0812ce90",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=64\n",
    "N_TRAINING_ITERATIONS = 2000\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"generator\" : generator,\n",
    "    \"discriminator\" : discriminator  \n",
    "}\n",
    "\n",
    "opts = {\n",
    "    \"generator\" : tf.keras.optimizers.Adam(),\n",
    "    \"discriminator\" : tf.keras.optimizers.Adam()\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "train_loop(BATCH_SIZE, N_TRAINING_ITERATIONS, models, opts, lie_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c1d351",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop(BATCH_SIZE, N_TRAINING_ITERATIONS, models, opts, lie_rate=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffa0489",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop(BATCH_SIZE, N_TRAINING_ITERATIONS, models, opts, lie_rate=0.00)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f91bd8",
   "metadata": {},
   "source": [
    "Getting a GAN to train successfully, even on MNIST, is no small challenge.   The previous cells will train a network for 2000 steps initally, and more as you choose to run it, and hopefully it eventually converges for you.  But there are a number of minor changes that will cause training to completely collapse:\n",
    " - Try using a different activation function (like relu, leaky_relu, sigmoid) - does it train?\n",
    " - Try not confusing the discriminator with label swapping.  Can it train?\n",
    " - Try turning off the label smoothing - still training?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0841dd",
   "metadata": {},
   "source": [
    "Running the training for a GAN is a pretty long process, even for mnist.  So there are included here pretrained weights you can use, for the remainder of this notebook, if your model didn't train well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad75a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save_weights(\"generator.h5\")\n",
    "discriminator.save_weights(\"discriminator.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e9cddc",
   "metadata": {},
   "source": [
    "# Exploring the abilities of the GAN network\n",
    "\n",
    "At this point, the GAN is reasonably trained.  We ran for 6000 iterations, which is only a handful of epochs, but the output digits are looking somewhat reasonable.  Let's explore how the GAN is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf233d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What happens when all 0s go in?\n",
    "zeros = numpy.zeros([1,100]).astype(numpy.float32)\n",
    "zero_input_image = generator(zeros)\n",
    "plt.imshow(zero_input_image.numpy().reshape(28,28));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f241826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What happens when all 1's go in?\n",
    "ones = numpy.ones([1,100]).astype(numpy.float32)\n",
    "ones_input_image = generator(ones)\n",
    "plt.imshow(ones_input_image.numpy().reshape(28,28));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baacd761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What happens when all 2's go in?\n",
    "twos = 2*numpy.ones([1,100]).astype(numpy.float32)\n",
    "twos_input_image = generator(twos)\n",
    "plt.imshow(twos_input_image.numpy().reshape(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42095e96",
   "metadata": {},
   "source": [
    "Let's vary the input more smoothly between two points.  We'll draw them randomly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b2ff99",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_point = numpy.random.uniform(-1,1,[1,100]).astype(numpy.float32)\n",
    "final_point   = numpy.random.uniform(-1,1,[1,100]).astype(numpy.float32)\n",
    "\n",
    "N_STEPS = 10\n",
    "\n",
    "output_image = numpy.zeros([28, (N_STEPS+1)*28])\n",
    "\n",
    "\n",
    "for i in range(N_STEPS + 1):\n",
    "    step = 1 - (N_STEPS - i )/ N_STEPS\n",
    "    input_point = initial_point + step * (final_point - initial_point) \n",
    "    this_image = generator(input_point).numpy().reshape(28,28)\n",
    "    output_image[:, i*28:(i+1)*28] = this_image\n",
    "\n",
    "fig = plt.figure(figsize=(16,4))\n",
    "plt.imshow(output_image);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0866c6b6",
   "metadata": {},
   "source": [
    "Try running this more, or using your own ideas for input, to see how the generator is smoothly transforming one digit into another."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da83d2d4",
   "metadata": {},
   "source": [
    "# Follow up Investigations for GANs\n",
    "\n",
    "GANs are tricky to train and can fall into all sorts of pitfalls.  The one show here works but at the same time, it's easy to make minor tweaks and see that it no longer trains.\n",
    "\n",
    "Do you want to learn more about GANs?  Here are some things you could explore doing with the basis from this notebook:\n",
    "\n",
    "1) Try changing some of the parameters of the network:\n",
    " - Input Size and distribution\n",
    " - Activation function\n",
    " - Dropout rates\n",
    " - What else can you change?\n",
    " \n",
    "2) Try changing how it is being trained:\n",
    " - Train both generator and discriminator simultaneously\n",
    " - Try different optimizers and learning rates\n",
    " - Instead of doing label swaps, try adding random noise to the real and fake images to make the classification harder.  \n",
    " - Can you turn down the label swapping as training progresses?\n",
    " \n",
    "3) Can you do more complicated GANs?  What about a network that turns every 7 into 1 one and vice-versa?  You will need a discriminator to train the generator, but also a classifier to train the generator.  How do you balance the loss?\n",
    " \n",
    "4) You could work on more datasets as well.  There is fashion MNIST, CIFAR, or explore a science domain dataset.\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda/2021-11-30",
   "language": "python",
   "name": "conda-2021-11-30"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
